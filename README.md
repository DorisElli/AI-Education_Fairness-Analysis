# AI-Education_Fairness-Analysis


This research explores the factors affecting student success and course outcomes using AI and predictive modeling tools. It analyzes the Open University Learning Analytics Dataset (OULAD) containing over 10 million rows of data on 32,593 students.

The goal is to gain insights into potential biases in AI systems used for educational purposes. Logistic regression and random forest classifiers are developed to predict student performance. The models are evaluated for accuracy, confusion matrix, precision and recall. 

Analysis reveals concerning gaps in online course completion rates and academic achievement based on gender, age, disability status and prior grades. For instance, the predictive model shows lower accuracy for male students compared to females.

The results highlight the need to address biases and promote inclusivity in AI systems for education. With ethical implementation, AI can assist in creating equitable learning environments. But biases could reinforce discrimination against certain groups.

This research contributes to the discussion on upholding transparency, fairness and accountability in AI-based decision making in education. Limitations include a focus on limited demographics and lack of qualitative data. Future work can build on these findings with a more holistic approach.
